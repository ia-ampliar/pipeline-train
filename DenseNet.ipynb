{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from utils.config import get_gpu_memory\n",
    "from utils.config import get_callbacks\n",
    "from models.train import train_model\n",
    "from utils.visualize import plot_training\n",
    "from utils.visualize import plot_confusion_matrix\n",
    "from utils.visualize import plot_roc_curve\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.evaluate import calculate_metrics\n",
    "\n",
    "from models.model import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se há GPU disponível\n",
    "get_gpu_memory()\n",
    "\n",
    "# Configurações\n",
    "IMG_SIZE = (224, 224)  # Tamanho da imagem\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100        # Número de épocas\n",
    "NUM_CLASSES = 2     # Número de classes\n",
    "PACIENTE = 7        # Paciência para o EarlyStopping\n",
    "DELTA = 0.001       # Delta para o ReduceLROnPlateau\n",
    "\n",
    "BASE_PATH = \"/mnt/efs-tcga/HEAL_Workspace/macenko_datas/\"\n",
    "\n",
    "# Caminhos para as imagens \n",
    "PATH_IMGS = BASE_PATH + 'splited'\n",
    "\n",
    "MODEL_NAME = \"denseNet121\" \n",
    "LOG_DIR =  f\"logs/fit/{MODEL_NAME}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "WEIGHT_PATH = BASE_PATH + \"weights/\"\n",
    "if not os.path.exists(WEIGHT_PATH):\n",
    "    os.makedirs(WEIGHT_PATH)\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = BASE_PATH + \"weights/checkpoint/\"\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "CHECKPOINT_ALL_PATH = BASE_PATH + \"weights/checkpoint_all/\"\n",
    "if not os.path.exists(CHECKPOINT_ALL_PATH):\n",
    "    os.makedirs(CHECKPOINT_ALL_PATH)\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/home/ec2-user/SageMaker/\" + \"models/\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "\n",
    "# Configurações de avaliação\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_PATH = BASE_PATH + \"splited/test/\"\n",
    "if not os.path.exists(EVAL_PATH):\n",
    "    os.makedirs(EVAL_PATH)\n",
    "\n",
    "# Configurações de teste\n",
    "TEST_BATCH_SIZE = 64\n",
    "TEST_PATH = BASE_PATH + \"splited/test/\"\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    os.makedirs(TEST_PATH)\n",
    "\n",
    "# Configurações de predição\n",
    "PRED_BATCH_SIZE = 64\n",
    "PRED_PATH = BASE_PATH + \"splited/test/\"\n",
    "if not os.path.exists(PRED_PATH):\n",
    "    os.makedirs(PRED_PATH)\n",
    "\n",
    "# Configurações de visualização\n",
    "VISUALIZE_BATCH_SIZE = 64\n",
    "VISUALIZE_PATH = BASE_PATH + \"splited/test/\"\n",
    "if not os.path.exists(VISUALIZE_PATH):\n",
    "    os.makedirs(VISUALIZE_PATH)\n",
    "\n",
    "\n",
    "md = Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = md.get_generators(PATH_IMGS, IMG_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelo DenseNet dentro da estratégia\n",
    "list_device = None\n",
    "strategy = md.get_strategy(list_device)\n",
    "with strategy.scope():\n",
    "    # Criando e compilando o modelo\n",
    "    model = md.create_densenet_model(pretrained=True, num_classes=NUM_CLASSES, img_size=IMG_SIZE)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping, checkpoint, checkpoint_all, tensorboard_callback = get_callbacks(model_name=MODEL_NAME,\n",
    "                                                                                 checkpoint_path=CHECKPOINT_PATH, \n",
    "                                                                                 checkpoint_all_path=CHECKPOINT_ALL_PATH, \n",
    "                                                                                 delta=DELTA, \n",
    "                                                                                 pacience=PACIENTE, \n",
    "                                                                                 log_dir=LOG_DIR,\n",
    "                                                                                 save_model_per_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = train_model(  model=model, \n",
    "                        model_name=MODEL_NAME,\n",
    "                        model_path=MODEL_PATH, \n",
    "                        weights_path=WEIGHT_PATH, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        epochs=EPOCHS, \n",
    "                        early_stopping=early_stopping, \n",
    "                        checkpoint=checkpoint, \n",
    "                        checkpoint_all=checkpoint_all,\n",
    "                        tensorboard_callback=tensorboard_callback, \n",
    "                        train_generator=train_generator, \n",
    "                        val_generator=validation_generator,\n",
    "                        initial_epoch=0,\n",
    "                        load_weight=None\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar evolução do treinamento\n",
    "plot_training(history)\n",
    "\n",
    "# Exibir instruções para visualizar o TensorBoard\n",
    "print(\"\\nPara visualizar o treinamento em tempo real, execute no terminal:\")\n",
    "print(\"tensorboard --logdir=logs/fit/{MODEL_NAME}\")\n",
    "print(\"Depois, abra no navegador: http://localhost:6006\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Avaliando o Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do modelo salvo\n",
    "tf.keras.backend.clear_session()\n",
    "model_path = BASE_PATH + \"weights/checkpoint_all/\" + f\"{MODEL_NAME}_epoch_10.keras\"\n",
    "\n",
    "# Carregar modelo\n",
    "model = load_model(model_path, compile=False)\n",
    "class_indices = test_generator.class_indices  # Índices das classes\n",
    "class_labels = list(class_indices.keys())  # Nomes das classes\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_true = test_generator.classes  # Classes verdadeiras\n",
    "y_pred_probs = model.predict(test_generator)  # Probabilidades preditas\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Classes preditas\n",
    "\n",
    "# Calcular métricas\n",
    "calculate_metrics(y_true, y_pred, class_labels, MODEL_NAME)\n",
    "\n",
    "# Plotar matriz de confusão\n",
    "plot_confusion_matrix(y_true, y_pred, class_labels, MODEL_NAME)\n",
    "\n",
    "# Plotar curva ROC\n",
    "plot_roc_curve(y_true, y_pred_probs, class_labels, MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Treinamento com mais épocas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar o modelo salvo\n",
    "INITIAL_EPOCH = 10  # Mude conforme necessário\n",
    "model = tf.keras.models.load_model(BASE_PATH + \"weights/checkpoint_all/\" + f'{MODEL_NAME}_epoch_{INITIAL_EPOCH}.keras')\n",
    "load_weight = BASE_PATH + \"weights/checkpoint_all/\" + f\"{MODEL_NAME}_epoch_{INITIAL_EPOCH}.keras\"\n",
    "\n",
    "# Verifica se há GPU disponível\n",
    "get_gpu_memory()\n",
    "\n",
    "# Configurações\n",
    "IMG_SIZE = (224, 224)  # Tamanho da imagem\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100        # Número de épocas\n",
    "NUM_CLASSES = 2     # Número de classes\n",
    "PACIENTE = 15        # Paciência para o EarlyStopping\n",
    "DELTA = 0.001       # Delta para o ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = md.get_generators(PATH_IMGS, IMG_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelo DenseNet dentro da estratégia\n",
    "list_device = None\n",
    "strategy = md.get_strategy(list_device)\n",
    "with strategy.scope():\n",
    "    # Criando e compilando o modelo\n",
    "    model = md.create_densenet_model(pretrained=True, num_classes=NUM_CLASSES, img_size=IMG_SIZE)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping, checkpoint, checkpoint_all, tensorboard_callback = get_callbacks(model_name=MODEL_NAME,\n",
    "                                                                                 checkpoint_path=CHECKPOINT_PATH, \n",
    "                                                                                 checkpoint_all_path=CHECKPOINT_ALL_PATH, \n",
    "                                                                                 delta=DELTA, \n",
    "                                                                                 pacience=PACIENTE, \n",
    "                                                                                 log_dir=LOG_DIR,\n",
    "                                                                                 save_model_per_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = train_model(\n",
    "                        model=model, \n",
    "                        model_name=MODEL_NAME,\n",
    "                        model_path=MODEL_PATH, \n",
    "                        weights_path=WEIGHT_PATH, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        epochs=EPOCHS, \n",
    "                        early_stopping=early_stopping, \n",
    "                        checkpoint=checkpoint, \n",
    "                        checkpoint_all=checkpoint_all,\n",
    "                        tensorboard_callback=tensorboard_callback, \n",
    "                        train_generator=train_generator, \n",
    "                        val_generator=validation_generator,\n",
    "                        initial_epoch=INITIAL_EPOCH,\n",
    "                        load_weight=load_weight\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar evolução do treinamento\n",
    "plot_training(history, MODEL_NAME)\n",
    "\n",
    "# Exibir instruções para visualizar o TensorBoard\n",
    "print(\"\\nPara visualizar o treinamento em tempo real, execute no terminal:\")\n",
    "print(f\"tensorboard --logdir=logs/fit/{MODEL_NAME}\")\n",
    "print(\"Depois, abra no navegador: http://localhost:6006\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Avaliando o Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do modelo salvo\n",
    "model_path = BASE_PATH + \"/models\" + f\"{MODEL_NAME}_model_224x224.keras\"\n",
    "\n",
    "# Carregar modelo\n",
    "model = load_model(model_path, compile=False)\n",
    "class_indices = test_generator.class_indices  # Índices das classes\n",
    "class_labels = list(class_indices.keys())  # Nomes das classes\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_true = test_generator.classes  # Classes verdadeiras\n",
    "y_pred_probs = model.predict(test_generator)  # Probabilidades preditas\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Classes preditas\n",
    "\n",
    "# Calcular métricas\n",
    "calculate_metrics(y_true, y_pred, class_labels, MODEL_NAME)\n",
    "\n",
    "# Plotar matriz de confusão\n",
    "plot_confusion_matrix(y_true, y_pred, class_labels, MODEL_NAME)\n",
    "\n",
    "# Plotar curva ROC\n",
    "plot_roc_curve(y_true, y_pred_probs, class_labels, MODEL_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
